pgwatch:
  image: "docker.io/cybertecpostgresql/pgwatch:latest"
  namespace: pgwatch
  postgres:
    enable_service_monitor: "true"
    enable_pg_sink: "true"
    settings:
      retention_days: 31
    # define is a database for the metrics needs to be created or if there is already an existing database
    create_metric_database: "true" #"false"
    new_pg_database:
      # Will be used for pgqwatch config only, if enable_pg_sink = "false"
      image: "docker.io/schmaetz/postgres:bookworm-17.4-1"
      volume:
        size: '10Gi'
        storageClass: 'crc-csi-hostpath-provisioner'
    # use_existing_database: # Will be used for pgqwatch config only, if enable_pg_sink = "false"
    #   endpoint: postgresql.local
    #   port:     '5432'
    #   database: PGWATCH_DATABASE
    #   sslmode:  require
    #   username: pgwatch_user
    #   password: PASSWORD_FOR_PGWATCH_USER
    sources: {}
      #- name: test1       # An arbitrary unique name for the monitored source
      #  kind: postgres    # One of the:
      #                      # - postgres
      #                      # - postgres-continuous-discovery
      #                      # - pgbouncer
      #                      # - pgpool
      #                      # - patroni
      #                      # - patroni-continuous-discovery
      #                      # - patroni-namespace-discover
      #                      # Defaults to postgres if not specified
      #  conn_str: postgresql://pgwatch:xyz@somehost/mydb
      #  preset_metrics: exhaustive # from list of presets defined in "metrics/preset-configs.yaml"
      #  custom_metrics:    # if both preset and custom are specified, custom wins
      #  preset_metrics_standby: # optional metrics configuration for standby / replica state, v1.8.1+
      #  custom_metrics_standby:
      #  include_pattern: # regex to filter databases to actually monitor for the "continuous" modes
      #  exclude_pattern:
      #  is_enabled: true
      #  group: default # just for logical grouping of DB hosts or for "sharding", i.e. splitting the workload between many gatherer daemons
      #  custom_tags:      # option to add arbitrary tags for every stored data row,
      #      aws_instance_id: i-0af01c0123456789a       # for example to fetch data from some other source onto a same Grafana graph

  prometheus:
    enable_prom_sink: "true"
    new_prometheus:
      create_prometheus: "false"
      create_alertmanager: "false"
      image: "prom/prometheus:main"
      settings:
        retention_days: 31
      volume:
        size: '10Gi'
        storageClass: 'crc-csi-hostpath-provisioner'
  grafana:
    enable_grafana: "true"
    enable_datasources:
      postgres: "true"
      prometheus: "false"
